{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wljifljkLf2",
        "outputId": "af0aefbe-f84a-4413-d648-350f542f2e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8XQwwL8tUA_",
        "outputId": "df820a69-8687-4aa7-eeed-193d29e4021a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL87k8nqkEU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827e1b90-f44c-4e39-cdde-4ce2192607c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqjU9l9JpkN_",
        "outputId": "23de31d1-9d03-4ba3-8eb9-02b3cc611b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.5 MB 4.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import EllipticBitcoinDataset"
      ],
      "metadata": {
        "id": "vXKiiw5wqmSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.transforms import NormalizeFeatures"
      ],
      "metadata": {
        "id": "6EqcC2Pqmzxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import Node2Vec"
      ],
      "metadata": {
        "id": "dDAyH3IYkQmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=EllipticBitcoinDataset(root=\"/\",transform=NormalizeFeatures())"
      ],
      "metadata": {
        "id": "I7eRlbhslTtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d2870708-69d5-46c4-b680-f5993b48d5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bc77eea613fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEllipticBitcoinDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNormalizeFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'EllipticBitcoinDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "print(50*'=')\n",
        "\n",
        "# There is only one graph in the dataset, use it as new data object\n",
        "data = dataset[0]\n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(data)\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX5bBiQamjZP",
        "outputId": "63ea03a7-b748-47e9-bf3a-ceff94582c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 1\n",
            "Number of features: 165\n",
            "Number of classes: 2\n",
            "==================================================\n",
            "Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])\n",
            "Number of nodes: 203769\n",
            "Number of edges: 234355\n",
            "Number of training nodes: 29894\n",
            "Training node label rate: 0.15\n",
            "Is undirected: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhN0cgodqPEc",
        "outputId": "55dee4c0-8e03-4243-968b-353ec0039093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.11.0+${CUDA}.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55JnqoYLq7TB",
        "outputId": "396225e5-efb0-4b72-9d85-53e51a880cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+.html\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.0.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 350, in run\n",
            "    global_options=[],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/wheel_builder.py\", line 337, in build\n",
            "    req, cache_dir, verify, build_options, global_options\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/wheel_builder.py\", line 224, in _build_one\n",
            "    req, output_dir, build_options, global_options\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/wheel_builder.py\", line 268, in _build_one_inside_env\n",
            "    tempd=temp_dir.path,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 95, in build_wheel_legacy\n",
            "    spinner=spinner,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 194, in call_subprocess\n",
            "    line = proc.stdout.readline()  # type: str\n",
            "  File \"/usr/lib/python3.7/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 213, in _main\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1366, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 894, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.7/logging/handlers.py\", line 71, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1127, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 130, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 616, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 566, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 104, in print_exception\n",
            "    type(value), value, tb, limit=limit).format(chain=chain):\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 508, in __init__\n",
            "    capture_locals=capture_locals)\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 363, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.7/traceback.py\", line 285, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.7/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 449, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 418, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.7/tokenize.py\", line 376, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_cluster"
      ],
      "metadata": {
        "id": "csuT4d6xkuKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "THKFIguqp_4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "id": "Hza_Kw9C6X9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric"
      ],
      "metadata": {
        "id": "4oiJmvPXuT4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Node2Vec(data.edge_index, embedding_dim=165, walk_length=20,\n",
        "             context_size=10, walks_per_node=10,num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
        "\n",
        "loader = model.loader(batch_size=128, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrWKGXevkUBA",
        "outputId": "387e1c9f-a337-471e-9e21-409efb19d5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
      ],
      "metadata": {
        "id": "DCPe8WCOrYHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    z = model()\n",
        "    acc = model.test(z[data.train_mask], data.y[data.train_mask],\n",
        "                     z[data.test_mask], data.y[data.test_mask],\n",
        "                     max_iter=10)\n",
        "    return acc\n",
        "\n",
        "\n",
        "for epoch in range(1, 100):\n",
        "    loss = train()\n",
        "    #acc = test()\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "nIkfkwqRrdDx",
        "outputId": "c4db3282-712d-4470-ce0e-0e80c313cd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 3.9642\n",
            "Epoch: 02, Loss: 1.5897\n",
            "Epoch: 03, Loss: 1.0164\n",
            "Epoch: 04, Loss: 0.8572\n",
            "Epoch: 05, Loss: 0.7968\n",
            "Epoch: 06, Loss: 0.7673\n",
            "Epoch: 07, Loss: 0.7507\n",
            "Epoch: 08, Loss: 0.7405\n",
            "Epoch: 09, Loss: 0.7337\n",
            "Epoch: 10, Loss: 0.7291\n",
            "Epoch: 11, Loss: 0.7258\n",
            "Epoch: 12, Loss: 0.7235\n",
            "Epoch: 13, Loss: 0.7218\n",
            "Epoch: 14, Loss: 0.7207\n",
            "Epoch: 15, Loss: 0.7199\n",
            "Epoch: 16, Loss: 0.7195\n",
            "Epoch: 17, Loss: 0.7193\n",
            "Epoch: 18, Loss: 0.7193\n",
            "Epoch: 19, Loss: 0.7194\n",
            "Epoch: 20, Loss: 0.7197\n",
            "Epoch: 21, Loss: 0.7200\n",
            "Epoch: 22, Loss: 0.7204\n",
            "Epoch: 23, Loss: 0.7208\n",
            "Epoch: 24, Loss: 0.7212\n",
            "Epoch: 25, Loss: 0.7216\n",
            "Epoch: 26, Loss: 0.7219\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-38ffdb989921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#acc = test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch:02d}, Loss: {loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-38ffdb989921>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sparse_adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    107\u001b[0m                           \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                           \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                           eps=group['eps'])\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msparse_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, eps, beta1, beta2, lr)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36mmake_sparse\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgrad_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z=model()"
      ],
      "metadata": {
        "id": "eIS492yhvD06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwjF09G5vKIU",
        "outputId": "459bc5f3-339a-4c8a-d654-fb034d90fb38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([203769, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.x+=z.cpu()"
      ],
      "metadata": {
        "id": "zD7MVkrycKvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TjdvyZHBzGC",
        "outputId": "7ee8dc15-a28b-4032-8830-9ade25017850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([203769, 165])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv #GATConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # Initialize the layers\n",
        "        self.conv1 = GCNConv(165, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.out = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First Message Passing Layer (Transformation)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Second Message Passing Layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Output layer\n",
        "        x = F.softmax(self.out(x), dim=1)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=256)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "TTGF-W_Jm9Hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7b04b9-8db3-4e6e-bf4b-36fb957d536c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(165, 256)\n",
            "  (conv2): GCNConv(256, 256)\n",
            "  (out): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "4x2j4T-orSIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9UdYCSN1XEgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lBLfCTNUOQ1",
        "outputId": "c46ebd08-86c3-42f9-b57c-fdd78d56c184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model=model.to(device)\n",
        "# Use GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "# Initialize Optimizer\n",
        "learning_rate = 0.01\n",
        "decay = 5e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=learning_rate,\n",
        "                             weight_decay=decay)\n",
        "# Define loss function (CrossEntropyLoss for Classification Problems with\n",
        "# probability distributions)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      # Use all data as input, because all nodes have node features\n",
        "      out = model(data.x.to(device), data.edge_index.to(device))\n",
        "      # Only use nodes with labels available for loss calculation --> mask\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def test():\n",
        "      model.eval()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      # Use the class with highest probability.\n",
        "      pred = out.argmax(dim=1)\n",
        "      # Check against ground-truth labels.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
        "      # Derive ratio of correct predictions.\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
        "      return test_acc\n",
        "\n",
        "losses = []\n",
        "for epoch in range(0, 1001):\n",
        "    loss = train()\n",
        "    losses.append(loss)\n",
        "    if epoch % 100 == 0:\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7FjiF6qIimK",
        "outputId": "a5a68559-4e03-4e60-c583-a50e868743e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 0.7101\n",
            "Epoch: 100, Loss: 0.4219\n",
            "Epoch: 200, Loss: 0.4205\n",
            "Epoch: 300, Loss: 0.4193\n",
            "Epoch: 400, Loss: 0.4122\n",
            "Epoch: 500, Loss: 0.3753\n",
            "Epoch: 600, Loss: 0.3623\n",
            "Epoch: 700, Loss: 0.3582\n",
            "Epoch: 800, Loss: 0.3558\n",
            "Epoch: 900, Loss: 0.3538\n",
            "Epoch: 1000, Loss: 0.3527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses]\n",
        "loss_indices = [i for i,l in enumerate(losses_float)]\n",
        "plt = sns.lineplot(loss_indices, losses_float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "df6nR8OIIsbK",
        "outputId": "da363826-e2b4-4ac5-c54c-5fbc59387c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test()\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjnpsmrqJAV0",
        "outputId": "01fa68ae-ff9a-4602-9c97-cccd59d6fae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def plt2arr(fig):\n",
        "    rgb_str = fig.canvas.tostring_rgb()\n",
        "    (w,h) = fig.canvas.get_width_height()\n",
        "    rgba_arr = np.fromstring(rgb_str, dtype=np.uint8, sep='').reshape((w,h,-1))\n",
        "    return rgba_arr\n",
        "\n",
        "\n",
        "def visualize(h, color, epoch):\n",
        "    fig = plt.figure(figsize=(5,5), frameon=False)\n",
        "    fig.suptitle(f'Epoch = {epoch}')\n",
        "    # Fit TSNE with 2 components\n",
        "    z = TSNE(n_components=2).fit_transform(out.detach().cpu().numpy())\n",
        "\n",
        "    # Create scatterplot from embeddings\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.scatter(z[:, 0],\n",
        "                z[:, 1],\n",
        "                s=70,\n",
        "                c=color.detach().cpu().numpy(),\n",
        "                cmap=\"Set2\")\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    # Convert to numpy\n",
        "    return plt2arr(fig)\n"
      ],
      "metadata": {
        "id": "9QvOImY2JDa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(data.x, data.edge_index)\n",
        "visualize(out, color=data.y, epoch=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsuoZCRHSHiL",
        "outputId": "f22d8996-3416-44da-8134-9a1595902e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwCXUPhwVxZW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}